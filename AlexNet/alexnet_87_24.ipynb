{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vEyE8sjbqsq6"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "\n",
        "from keras.optimizers.legacy import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "olRWl99QK90C"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3erhsEUQK5KU"
      },
      "outputs": [],
      "source": [
        "def AlexNet(num_classes=10):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Feature extraction layers\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(384, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(2048))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(2048))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mMcXYsHWyMRy"
      },
      "outputs": [],
      "source": [
        "alexnet = AlexNet(num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNbjF4QrytyX"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TxfZTwnAq-og"
      },
      "outputs": [],
      "source": [
        "class cifar10vgg:\n",
        "    def __init__(self, model, lr, train=True):\n",
        "        self.num_classes = 10\n",
        "        self.weight_decay = 0.0005\n",
        "        self.x_shape = [32, 32, 3]\n",
        "\n",
        "        self.model = model\n",
        "        if train:\n",
        "            self.model = self.train(self.model, lr)\n",
        "        else:\n",
        "            self.model.load_weights('cifar10vgg.h5')\n",
        "\n",
        "    def normalize(self, X_train, X_test):\n",
        "        mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train - mean) / (std + 1e-7)\n",
        "        X_test = (X_test - mean) / (std + 1e-7)\n",
        "        return X_train, X_test\n",
        "\n",
        "    def normalize_production(self, x):\n",
        "        mean = 120.707\n",
        "        std = 64.15\n",
        "        return (x - mean) / (std + 1e-7)\n",
        "\n",
        "    def predict(self, x, normalize=True, batch_size=50):\n",
        "        if normalize:\n",
        "            x = self.normalize_production(x)\n",
        "        return self.model.predict(x, batch_size)\n",
        "\n",
        "    def train(self, model, lr):\n",
        "        batch_size = 128\n",
        "        maxepoches = 250\n",
        "        learning_rate = lr\n",
        "        lr_decay = 1e-6\n",
        "        lr_drop = 20\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train, x_test = self.normalize(x_train, x_test)\n",
        "\n",
        "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        def lr_scheduler(epoch):\n",
        "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=15,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "        datagen.fit(x_train)\n",
        "\n",
        "        sgd = SGD(learning_rate=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "        historytemp = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                                steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                                epochs=maxepoches,\n",
        "                                validation_data=(x_test, y_test),\n",
        "                                callbacks=[reduce_lr, early_stopping],\n",
        "                                verbose=2)\n",
        "        model.save_weights('cifar10vgg.h5')\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "so1R9mOaNjHc",
        "outputId": "4b730752-b802-4917-ecc6-24def0527b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "390/390 - 30s - loss: 1.9107 - accuracy: 0.2762 - val_loss: 1.4887 - val_accuracy: 0.4507 - lr: 0.0100 - 30s/epoch - 76ms/step\n",
            "Epoch 2/250\n",
            "390/390 - 30s - loss: 1.4455 - accuracy: 0.4641 - val_loss: 1.3187 - val_accuracy: 0.5364 - lr: 0.0100 - 30s/epoch - 77ms/step\n",
            "Epoch 3/250\n",
            "390/390 - 28s - loss: 1.2195 - accuracy: 0.5576 - val_loss: 1.2557 - val_accuracy: 0.5833 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 4/250\n",
            "390/390 - 28s - loss: 1.0502 - accuracy: 0.6233 - val_loss: 0.8687 - val_accuracy: 0.6887 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 5/250\n",
            "390/390 - 28s - loss: 0.9302 - accuracy: 0.6705 - val_loss: 0.8699 - val_accuracy: 0.7028 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 6/250\n",
            "390/390 - 28s - loss: 0.8463 - accuracy: 0.7056 - val_loss: 0.8436 - val_accuracy: 0.7250 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 7/250\n",
            "390/390 - 28s - loss: 0.7813 - accuracy: 0.7295 - val_loss: 0.7005 - val_accuracy: 0.7653 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 8/250\n",
            "390/390 - 28s - loss: 0.7214 - accuracy: 0.7508 - val_loss: 0.7127 - val_accuracy: 0.7662 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 9/250\n",
            "390/390 - 30s - loss: 0.6738 - accuracy: 0.7661 - val_loss: 0.6831 - val_accuracy: 0.7752 - lr: 0.0100 - 30s/epoch - 78ms/step\n",
            "Epoch 10/250\n",
            "390/390 - 28s - loss: 0.6386 - accuracy: 0.7795 - val_loss: 0.5894 - val_accuracy: 0.8051 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 11/250\n",
            "390/390 - 28s - loss: 0.6016 - accuracy: 0.7943 - val_loss: 0.5560 - val_accuracy: 0.8168 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 12/250\n",
            "390/390 - 28s - loss: 0.5756 - accuracy: 0.8021 - val_loss: 0.5764 - val_accuracy: 0.8085 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 13/250\n",
            "390/390 - 28s - loss: 0.5442 - accuracy: 0.8130 - val_loss: 0.5355 - val_accuracy: 0.8258 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 14/250\n",
            "390/390 - 28s - loss: 0.5194 - accuracy: 0.8212 - val_loss: 0.5533 - val_accuracy: 0.8179 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 15/250\n",
            "390/390 - 30s - loss: 0.4981 - accuracy: 0.8288 - val_loss: 0.5143 - val_accuracy: 0.8327 - lr: 0.0100 - 30s/epoch - 77ms/step\n",
            "Epoch 16/250\n",
            "390/390 - 28s - loss: 0.4805 - accuracy: 0.8339 - val_loss: 0.5134 - val_accuracy: 0.8319 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 17/250\n",
            "390/390 - 28s - loss: 0.4566 - accuracy: 0.8428 - val_loss: 0.5154 - val_accuracy: 0.8308 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 18/250\n",
            "390/390 - 28s - loss: 0.4402 - accuracy: 0.8505 - val_loss: 0.4421 - val_accuracy: 0.8533 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 19/250\n",
            "390/390 - 28s - loss: 0.4264 - accuracy: 0.8531 - val_loss: 0.4670 - val_accuracy: 0.8445 - lr: 0.0100 - 28s/epoch - 72ms/step\n",
            "Epoch 20/250\n",
            "390/390 - 28s - loss: 0.4057 - accuracy: 0.8603 - val_loss: 0.4831 - val_accuracy: 0.8423 - lr: 0.0100 - 28s/epoch - 71ms/step\n",
            "Epoch 21/250\n",
            "390/390 - 28s - loss: 0.3453 - accuracy: 0.8808 - val_loss: 0.4311 - val_accuracy: 0.8650 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 22/250\n",
            "390/390 - 30s - loss: 0.3262 - accuracy: 0.8884 - val_loss: 0.4623 - val_accuracy: 0.8542 - lr: 0.0050 - 30s/epoch - 78ms/step\n",
            "Epoch 23/250\n",
            "390/390 - 28s - loss: 0.3133 - accuracy: 0.8913 - val_loss: 0.4439 - val_accuracy: 0.8602 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 24/250\n",
            "390/390 - 28s - loss: 0.3043 - accuracy: 0.8958 - val_loss: 0.4292 - val_accuracy: 0.8645 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 25/250\n",
            "390/390 - 28s - loss: 0.2968 - accuracy: 0.8986 - val_loss: 0.4501 - val_accuracy: 0.8622 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 26/250\n",
            "390/390 - 28s - loss: 0.2910 - accuracy: 0.8984 - val_loss: 0.4389 - val_accuracy: 0.8634 - lr: 0.0050 - 28s/epoch - 72ms/step\n",
            "Epoch 27/250\n",
            "390/390 - 28s - loss: 0.2778 - accuracy: 0.9048 - val_loss: 0.4487 - val_accuracy: 0.8632 - lr: 0.0050 - 28s/epoch - 73ms/step\n",
            "Epoch 28/250\n",
            "390/390 - 27s - loss: 0.2706 - accuracy: 0.9072 - val_loss: 0.4078 - val_accuracy: 0.8724 - lr: 0.0050 - 27s/epoch - 70ms/step\n",
            "Epoch 29/250\n",
            "390/390 - 29s - loss: 0.2672 - accuracy: 0.9066 - val_loss: 0.4416 - val_accuracy: 0.8632 - lr: 0.0050 - 29s/epoch - 75ms/step\n",
            "Epoch 30/250\n",
            "390/390 - 28s - loss: 0.2574 - accuracy: 0.9102 - val_loss: 0.4285 - val_accuracy: 0.8682 - lr: 0.0050 - 28s/epoch - 73ms/step\n",
            "Epoch 31/250\n",
            "390/390 - 28s - loss: 0.2591 - accuracy: 0.9107 - val_loss: 0.4109 - val_accuracy: 0.8759 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 32/250\n",
            "390/390 - 28s - loss: 0.2482 - accuracy: 0.9143 - val_loss: 0.4118 - val_accuracy: 0.8756 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 33/250\n",
            "390/390 - 28s - loss: 0.2426 - accuracy: 0.9162 - val_loss: 0.4291 - val_accuracy: 0.8717 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 34/250\n",
            "390/390 - 28s - loss: 0.2388 - accuracy: 0.9166 - val_loss: 0.4868 - val_accuracy: 0.8619 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 35/250\n",
            "390/390 - 29s - loss: 0.2344 - accuracy: 0.9175 - val_loss: 0.4290 - val_accuracy: 0.8739 - lr: 0.0050 - 29s/epoch - 74ms/step\n",
            "Epoch 36/250\n",
            "390/390 - 28s - loss: 0.2265 - accuracy: 0.9214 - val_loss: 0.4338 - val_accuracy: 0.8716 - lr: 0.0050 - 28s/epoch - 72ms/step\n",
            "Epoch 37/250\n",
            "390/390 - 28s - loss: 0.2238 - accuracy: 0.9220 - val_loss: 0.4425 - val_accuracy: 0.8696 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 38/250\n",
            "390/390 - 28s - loss: 0.2168 - accuracy: 0.9253 - val_loss: 0.4859 - val_accuracy: 0.8598 - lr: 0.0050 - 28s/epoch - 72ms/step\n",
            "Epoch 39/250\n",
            "390/390 - 29s - loss: 0.2108 - accuracy: 0.9265 - val_loss: 0.4437 - val_accuracy: 0.8728 - lr: 0.0050 - 29s/epoch - 75ms/step\n",
            "Epoch 40/250\n",
            "390/390 - 28s - loss: 0.2074 - accuracy: 0.9275 - val_loss: 0.4311 - val_accuracy: 0.8746 - lr: 0.0050 - 28s/epoch - 71ms/step\n",
            "Epoch 41/250\n",
            "390/390 - 28s - loss: 0.1721 - accuracy: 0.9399 - val_loss: 0.4196 - val_accuracy: 0.8790 - lr: 0.0025 - 28s/epoch - 71ms/step\n",
            "Epoch 42/250\n",
            "390/390 - 28s - loss: 0.1613 - accuracy: 0.9436 - val_loss: 0.4527 - val_accuracy: 0.8759 - lr: 0.0025 - 28s/epoch - 71ms/step\n",
            "Epoch 43/250\n",
            "390/390 - 28s - loss: 0.1582 - accuracy: 0.9450 - val_loss: 0.4596 - val_accuracy: 0.8752 - lr: 0.0025 - 28s/epoch - 72ms/step\n",
            "200/200 [==============================] - 1s 5ms/step\n",
            "the validation 0/1 loss is:  0.1276\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "\n",
        "    y_train = keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    model = cifar10vgg(alexnet, 0.01)\n",
        "\n",
        "    predicted_x = model.predict(x_test)\n",
        "    residuals = np.argmax(predicted_x,1)!=np.argmax(y_test,1)\n",
        "\n",
        "    loss = sum(residuals)/len(residuals)\n",
        "    print(\"the validation 0/1 loss is: \",loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3647WwGEjnd",
        "outputId": "17ba35a4-eaa3-4fa3-a761-62aab1b534ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8724\n"
          ]
        }
      ],
      "source": [
        "# Test accuracy calculation without using evaluate\n",
        "correct_predictions = np.sum(np.argmax(predicted_x, axis=1) == np.argmax(y_test, axis=1))\n",
        "test_accuracy = correct_predictions / len(y_test)\n",
        "print(\"Test accuracy:\", test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
